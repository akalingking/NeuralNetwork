"""
Train Mean accuracy 0.880972 (+/-0.096157.5) rmse 0.328452 (+/-0.105580.5)
Test  Mean accuracy 0.780247 (+/-0.057854.5) rmse 0.464895 (+/-0.060214.5)
Train: Score for neural-blend accuracy=0.896380 rmse=0.321901
Valid: Score for neural-blend accuracy=0.844444.5 rmse=0.394405.5

Train Mean accuracy 0.939028 (+/-0.007256.5) rmse 0.246505 (+/-0.014404.5)
Test  Mean accuracy 0.772840 (+/-0.032757.5) rmse 0.475402 (+/-0.033955.5)
Train: Score for neural-blend accuracy=0.923845 rmse=0.275962
Valid: Score for neural-blend accuracy=0.822222.5 rmse=0.421637.5

Train Mean accuracy 0.937361 (+/-0.010622.5) rmse 0.249436 (+/-0.020502.5)
Test  Mean accuracy 0.788889 (+/-0.027853.5) rmse 0.458455 (+/-0.030504.5)
Train: Score for neural-blend accuracy=0.917603 rmse=0.287049
Valid: Score for neural-blend accuracy=0.855556.5 rmse=0.380058.5

Train Mean accuracy 0.930417 (+/-0.016486.5) rmse 0.262046 (+/-0.030254.5)
Test  Mean accuracy 0.776543 (+/-0.047318.5) rmse 0.469983 (+/-0.050722.5)
Train: Score for neural-blend accuracy=0.916355 rmse=0.289215
Valid: Score for neural-blend accuracy=0.811111.5 rmse=0.434613.5

.70813
nn1,nn2,nn3,nn4
Train Mean accuracy 0.932361 (+/-0.011671.5) rmse 0.259195 (+/-0.021373.5)
Test  Mean accuracy 0.785185 (+/-0.025421.5) rmse 0.462656 (+/-0.027648.5)
Train: Score for neural-blend accuracy=0.928839 rmse=0.266760
Valid: Score for neural-blend accuracy=0.822222.5 rmse=0.421637.5

Train Mean accuracy 0.889028 (+/-0.018649.5) rmse 0.331995 (+/-0.027412.5)
Test  Mean accuracy 0.786420 (+/-0.028180.5) rmse 0.461059 (+/-0.031695.5)
Train: Score for neural-blend accuracy=0.943820 rmse=0.237023
Valid: Score for neural-blend accuracy=0.855556.5 rmse=0.380058.5

==========================================================
"""
import datetime
import numpy as np
import pandas as pd
from scipy import stats
from sklearn import metrics
from sklearn import metrics
from sklearn.cross_validation import StratifiedKFold
from sklearn import grid_search
from sklearn import cross_validation as cv
from sklearn.decomposition import PCA
from sklearn.svm import SVC
from sklearn.svm import LinearSVC
import titanicdataset

from boostxg import GBC_xg

from sklearn.ensemble import (BaggingClassifier, 
                              RandomForestClassifier, 
                              GradientBoostingClassifier)
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier,ExtraTreeClassifier
import neuralnetwork_f as N


class Blending(object):
    def __init__(self, clfs=[], combiner=LogisticRegression(), n_folds=10,train_size=0.9, random_state=None):
        self.set_params(clfs, combiner, n_folds,train_size)

    def set_params(self, clfs, combiner=LogisticRegression(), n_folds=10,train_size=0.9, random_state=None):
        self.clfs = clfs
        self.combiner = combiner
        self.n_folds = n_folds
        self.train_size = train_size
        self.random_state = random_state

    def fit(self, X, y):
        dataset_blend_train = np.zeros((X.shape[0], len(self.clfs)))
        #skf = list(StratifiedKFold(y, n_folds))
        skf = cv.StratifiedShuffleSplit(y, n_iter=self.n_folds, train_size=self.train_size, random_state=self.random_state)
        print len(self.clfs)
        for j in range(len(self.clfs)):
            clf = self.clfs[j]
            print j, clf
            dataset_blend_test_j = np.zeros((X.shape[0], len(skf)))
            accuracy_train = []
            accuracy_test = []
            rmse_train = []
            rmse_test = []
            
            for i, (train, test) in enumerate(skf):
                x_train = X[train]
                y_train = y[train]
                x_test = X[test]
                y_test = y[test]
                clf.fit(x_train, y_train)
                y_train_pred = clf.predict_proba(x_train)[:,1]
                
                accuracy_train.append (metrics.accuracy_score(y_train, [(1 if x > .5 else 0) for x in y_train_pred]))
                rmse_train.append (np.sqrt(metrics.mean_squared_error(y_train, [(1 if x > .5 else 0) for x in y_train_pred])))

                y_test_pred = clf.predict_proba(x_test)[:,1]
                dataset_blend_train[test, j] = y_test_pred
                
                accuracy_test.append (metrics.accuracy_score(y_test, [(1 if x > .5 else 0) for x in y_test_pred]))
                rmse_test.append(np.sqrt(metrics.mean_squared_error(y_test, [(1 if x > .5 else 0) for x in y_test_pred])))
                
            print ('Train Mean accuracy %f (+/-%f.5) rmse %f (+/-%f.5)' % \
                   (np.mean(accuracy_train), np.std(accuracy_train), np.mean(rmse_train), np.std(rmse_train)))
            print ('Test  Mean accuracy %f (+/-%f.5) rmse %f (+/-%f.5)' % \
                   (np.mean(accuracy_test), np.std(accuracy_test), np.mean(rmse_test), np.std(rmse_test)))

        self.combiner.fit(dataset_blend_train, y)


    def predict_proba(self, X):
        dataset_blend_test = np.zeros((X.shape[0], len(self.clfs)))
        for j, clf in enumerate(self.clfs):
            dataset_blend_test[:,j] = clf.predict_proba(X)[:,1]

        y_pred = self.combiner.predict_proba(dataset_blend_test)[:,1]

        #print "Linear stretch of predictions to [0,1]"
        y_pred = (y_pred - y_pred.min()) / (y_pred.max() - y_pred.min())
        return y_pred


    def predict(self, X):
        result = self.predict_proba(X)
        y_pred = [(1 if x > .5 else 0) for x in result]
        return y_pred
    
    def score(self, X, y, sample_weight=None):
        y_pred = self.predict(X)
        return metrics.accuracy_score(y, y_pred)
        
    

def getfiletime():
    datetime_ = datetime.datetime.now()
    filetime = str(datetime_.date()).replace('-','')
    filetime += '_' + str(datetime_.time()).replace(':','')
    filetime = filetime.replace('.','')
    return filetime


def process_test_data(params, estimator, x_test_index, x_test):
    y_test_pred = estimator.predict(x_test)
    result = np.c_[x_test_index, y_test_pred].astype(int)
    submission = pd.DataFrame(result, columns=['PassengerId', 'Survived'])

    filename = '../submission/submission_' + params['Model'] + '_' \
                + '_' + getfiletime() +'.csv'

    submission.to_csv(filename, index=False)



def main():
    # 1. Generate data
    print 'Running', __file__, '...'

    params =    {
                'Model'                 : 'neural-blend',
                'TrainFile'             : '../data/train.csv',
                'TestFile'              : '../data/test.csv',
                'TrainSize'             : .9
                }

    df = titanicdataset.load_train_data(params)
    train_data = df.values
    # Start in the PClass column, we will not be using the passengerid
    X_train = train_data[:,2:]
    Y_train = train_data[:,0].astype(int)
    # Partition training data
    trainSize = int(params['TrainSize'] * np.size(Y_train))
    x_train, x_valid = X_train[:trainSize, :], X_train[trainSize:,:]
    y_train, y_valid = Y_train[:trainSize], Y_train[trainSize:]

    df = titanicdataset.load_test_data(params)
    X_test = df.values
    x_test_index = X_test[:,0]
    x_test = X_test[:,1:]

    print 'Analyzing training data ', params['Model'], 'datapoints=', x_train.shape[0], 'features=',x_train.shape[1]

    rng = np.random.RandomState(5000)

    
    fixed_params = dict(desired_error=0.0001, epoch=300, show=50)
    param_keys = ['connection_rate', 'network', 'learning_rate', 
                  'training_algorithm', 'learning_momentum', 
                  'initial_weight', 'output_activation', 'hidden_activation']
    
    param_values = [0.7, [9, 72, 72, 72, 1], 0.09, 2, 0.03, 0.82, 3, 5]
    params_nn = dict(zip(param_keys,param_values))
    params_nn.update(fixed_params)
    nn1 = N.NeuralNetwork()
    nn1.set_params(**params_nn)
    
    param_values = [0.7, [9, 72, 72, 72, 1], 0.06, 2, 0.04, 0.74, 3, 5]
    params_nn = dict(zip(param_keys,param_values))
    params_nn.update(fixed_params)
    nn2 = N.NeuralNetwork()
    nn2.set_params(**params_nn)
    
    param_values = [0.7, [9, 72, 72, 72, 1], 0.08, 2, 0.04, 0.83, 3, 5]
    params_nn = dict(zip(param_keys,param_values))
    params_nn.update(fixed_params)
    nn3 = N.NeuralNetwork()
    nn3.set_params(**params_nn)
    
    param_values = [0.7, [9, 72, 72, 72, 1], 0.06, 2, 0.03, 0.82, 3, 5]
    params_nn = dict(zip(param_keys,param_values))
    params_nn.update(fixed_params)
    nn4 = N.NeuralNetwork()
    nn4.set_params(**params_nn)
    
    param_values = [0.7, [9, 72, 72, 72, 1], 0.08, 2, 0.04, 0.74, 3, 5]
    params_nn = dict(zip(param_keys,param_values))
    params_nn.update(fixed_params)
    nn5 = N.NeuralNetwork()
    nn5.set_params(**params_nn)

    param_values = [0.7, [9, 72, 72, 72, 1], 0.09, 2, 0.04, 0.74, 3, 5]
    params_nn = dict(zip(param_keys,param_values))
    params_nn.update(fixed_params)
    nn6 = N.NeuralNetwork()
    nn6.set_params(**params_nn)
    
    param_values = [0.7, [9, 72, 72, 72, 1], 0.08, 2, 0.03, 0.7, 3, 5]
    params_nn = dict(zip(param_keys,param_values))
    params_nn.update(fixed_params)
    nn7 = N.NeuralNetwork()
    nn7.set_params(**params_nn)
    
    param_values = [0.7, [9, 36, 36, 36, 36, 1], 0.03, 2, 0.04, 0.74, 3, 5]
    params_nn = dict(zip(param_keys,param_values))
    params_nn.update(fixed_params)
    nn8 = N.NeuralNetwork()
    nn8.set_params(**params_nn)
    
    param_values = [0.7, [9, 18, 18, 18, 1], 0.08, 2, 0.03, 0.81, 3, 5]
    params_nn = dict(zip(param_keys,param_values))
    params_nn.update(fixed_params)
    nn9 = N.NeuralNetwork()
    nn9.set_params(**params_nn)
    
    clf_params =    dict(clfs       = [nn1,nn2,nn3,nn4,nn5,nn6,nn7,nn8,nn9],
                        combiner    = LogisticRegression(),
                        n_folds     = 10,
                        train_size  = .9,
                        random_state = rng)
    

    print clf_params
    classifier = Blending()
    classifier.set_params(**clf_params)
    classifier.fit(x_train, y_train)
    
    # Needs to implement sklearn API to be able to do this
#     scores = cv.cross_val_score(classifier, x_train, y_train, cv=10)
#     print('Estimated score: %0.5f (+/- %0.5f)' % (scores.mean(), scores.std()))
    
    y_train_pred = classifier.predict(x_train)
 
    print"Train: Score for %s accuracy=%f rmse=%f" % (params['Model'],
        metrics.accuracy_score(y_train, y_train_pred),
        np.sqrt(metrics.mean_squared_error(y_train, y_train_pred)))


    y_valid_pred = classifier.predict(x_valid)

    print"Valid: Score for %s accuracy=%f.5 rmse=%f.5" % (params['Model'],
        metrics.accuracy_score(y_valid, y_valid_pred),
        np.sqrt(metrics.mean_squared_error(y_valid, y_valid_pred)))


    #print 'Analyzing test data ', params['Model'], 'datapoints=', x_test.shape[0], 'features=',x_test.shape[1]
    process_test_data(params, classifier, x_test_index, x_test)



if __name__ == '__main__':
    main()