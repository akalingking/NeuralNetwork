
import numpy as np
import itertools
import neuralnetwork_f as N
import titanicdataset

rng = np.random.RandomState(5000)

chromosomes = dict(
        network           = [#[9,18,1],[9,24,1],[9,36,1],[9,45,1],[9.54,1],[9.63,1],
                             [9,18,18,1],[9,24,24,1],[9,36,36,1],[9,45,45,1],[9.54,54,1],[9.63,63,1],[9.72,72,1],[9.81,81,1],
                             [9,18,18,18,1],[9,24,24,24,1],[9,36,36,36,1],[9,45,45,45,1],[9.54,54,54,1],[9.63,63,63,1],[9.72,72,72,1],[9.81,81,81,1],
                             [9,18,18,18,18,1],[9,24,24,24,24,1],[9,36,36,36,36,1],[9,45,45,45,45,1],[9.54,54,54,54,1],[9.63,63,63,63,1],[9.72,72,72,72,1],[9.81,81,81,81,1],
                             ],
        connection_rate   = [1.0,.9,.8,.7,.6,.5],
        learning_rate     = [.005,.008,.009,.01,.02,.03,.04,.05,.06,.07,.08,.09,.1],
        learning_momentum = [.001, .002, .003, .004, .005,.006,.007,.008,.009,.01,.02,.03,.04,.05],
        initial_weight    = [.70,.71,.72,.73,.74, .75, .76, .77, .78,.79,.8,.81,.82,.83,.84,.85],
        hidden_activation = [N.SIGMOID,N.SIGMOID_SYMMETRIC,N.SIGMOID_STEPWISE, N.SIGMOID_SYMMETRIC_STEPWISE],
        output_activation = [N.SIGMOID,N.SIGMOID_SYMMETRIC,N.SIGMOID_STEPWISE, N.SIGMOID_SYMMETRIC_STEPWISE],
        training_algorithm = [N.TRAIN_INCREMENTAL, N.TRAIN_BATCH, N.TRAIN_QUICKPROP, N.TRAIN_RPROP, N.TRAIN_SARPROP],
    )

chromosomes_fixed = dict(
                         desired_error     = 0.0001,
                         epoch             = 200,
                         show              = 0,
                         )

def individual():
    keys = chromosomes.keys()
    individual_ = []
    for i,key in enumerate(keys):
        index = rng.randint(0, len(chromosomes[key]), 1) 
        individual_.append(chromosomes[key][index])
    
    return individual_
     

def population(size=100):
    population_ = []
    while len(population_) < size:
        individual_ = individual()
        if individual_ not in population_:
            population_.append(individual_)
        else:
            print 'population: individual already in population.'
        
    return population_


def fitness (model, individual, x_train, y_train, x_valid, y_target, target):
    dict_ = dict(zip(chromosomes.keys(), individual))
    dict_.update(chromosomes_fixed)
    model.set_params(**dict_)
    #model.set_params(**dict(zip(chromosomes.keys(), individual)))
    model.fit(x_train, y_train)
    score = model.score(x_train, y_train)
    #print 'fitness for %s score=%f' % (dict(zip(chromosomes.keys(), individual)), score)
    #print 'fitness header %s' % (score, dict_.keys())
    print 'fitness: score=%f for %s' % (score, dict_.values())
    return abs(score - target)


def grade(model, pop, x_train, y_train, x_valid, y_valid, target):
    summed = 0
    for item in pop:
        summed += fitness(model, item, x_train, y_train, x_valid, y_valid, target)
    mean_ = summed / (len(pop) * 1.)
    
    #print 'grade mean=%f' % (mean_)
    
    return mean_
        
    

def evolve(model, pop, x_train, y_train, x_valid, y_valid, target, 
           retain=0.2, random_select=0.05, mutate=0.01):
    graded = [(fitness(model, ind, x_train, y_train, x_valid, y_valid, target),ind) for ind in pop]
    graded = [ind[1] for ind in sorted(graded)]
    retain_length = int(len(graded) * retain)
    parents = graded[:retain_length]
    
    # randomly add other individuals to
    # promote genetic diversity
    '''for individual_ in graded[retain_length:]:
        if random_select > np.random.random():
            parents.append(individual_)'''
    random_individual = []
    for individual_ in graded[retain_length:]:
        # Select only from graded[retain_length:]
        if random_select > rng.rand():
            individual_ = graded[rng.randint(retain_length, len(graded)-1, 1)]
            if individual_ not in random_individual:
                random_individual.append(individual_)
            else:
                print 'evolve: random individual already present %d=%d from %d' % (retain_length, len(random_individual), len(graded))
    
    print 'extending parent of %d random individuals' % len(random_individual)
    parents.extend(random_individual)
            
            
    # Mutate chromosomes of some individuals
    for individual_ in parents:
        if mutate > rng.rand():
            pos_to_mutate = rng.randint(0,len(individual_) - 1, 1)
            keys = chromosomes.keys()
            # get a random value
            parameter_index = rng.randint(0, len(chromosomes[keys[pos_to_mutate]]), 1) 
            individual_[pos_to_mutate] = chromosomes[keys[pos_to_mutate]][parameter_index]
    
    # Crossover to create children
    allow_duplicate_ = False
    max_search_for_mate_cnt = 10
    search_for_mate_cnt = 0 
    parents_len = len(parents)
    desired_len = len(pop) - parents_len
    children = []
    while (len(children) < desired_len):
        male = rng.randint(0, parents_len - 1, 1)
        female = rng.randint(0, parents_len - 1, 1)
        if male != female:
            male = parents[male]
            female = parents[female]
            half = len(male) / 2
            child = male[:half] + female[half:]
            # make sure we have enough permutations
            if child not in children:
                children.append(child)
            else:
                print 'evolve: Child already in population parents=%d children=%d desired=%d' % \
                    (parents_len, len(children), desired_len)
        else:
            search_for_mate_cnt += 1
            if search_for_mate_cnt == max_search_for_mate_cnt:
                while (True):
                    random_individual_ = graded[rng.randint(retain_length, len(graded)-1, 1)]
                    if random_individual_ not in parents:
                        print 'evolve: Adding new parent randomly.'
                        parents.append(random_individual_)
                        parents_len = len(parents)
                        desired_len = len(pop) - parents_len
                        search_for_mate_cnt = 0
                        break;
                    else:
                        #for i in xrange(3): # make this 3 attempts 
                        random_parent = graded[rng.randint(retain_length, len(graded)-1, 1)]
                        pos_to_mutate = rng.randint(0,len(random_parent) - 1, 1)
                        keys = chromosomes.keys()
                        # get a random chromosome
                        parameter_index = rng.randint(0, len(chromosomes[keys[pos_to_mutate]]), 1) 
                        # alter the chromosome
                        random_parent[pos_to_mutate] = chromosomes[keys[pos_to_mutate]][parameter_index]
                        if random_parent not in parents:
                            print 'evolve: Adding new parent by mutation.'
                            parents.append(random_parent)
                            parents_len = len(parents)
                            desired_len = len(pop) - parents_len
                            search_for_mate_cnt = 0
                            break
                        else:
                            print 'evolve: Failed to add mutated parent'
                                
                        #if search_for_mate_cnt == 0:
                        #    break;
                        
            print 'evolve: Got same gender on crossover, retry search for male and female...'
    
    parents.extend(children)
    # Make sure we keep teh sam size
    assert len(parents) == len(pop)
    return parents


def find_best_individual(model, pop, x_train, y_train, x_valid, y_valid, target):
    grades = [(fitness(model, ind, x_train, y_train, x_valid, y_valid, target), ind) for ind in pop]
    return sorted(grades)


            
def loaddataset():
    params =    {   'TrainFile'             : '../data/train.csv',
                    'TestFile'              : '../data/test.csv',
                    'TrainSize'             : 0.9
                }

    df = titanicdataset.load_train_data(params)
    train_data = df.values
    
    # Start in the PClass column, we will not be using the passengerid
    X_train = train_data[:,2:]
    Y_train = train_data[:,0].astype(int)
    
    # Partition training data
    trainSize = int(params['TrainSize'] * np.size(Y_train))
    x_train, x_valid = X_train[:trainSize, :], X_train[trainSize:,:]
    y_train, y_valid = Y_train[:trainSize], Y_train[trainSize:]
    
    return [x_train, y_train, x_valid, y_valid]





def main():
    max_retention_rate = 0.4
    min_retention_rate = 0.2
    retention_rate_delta = 0.2
    random_select = 0.05
    mutate = 0.01
    
    #target = 1.0 # accuracy
    target = 0.0 # rmse
    n_generation = 20
    n_population = 20
    
    model = N.NeuralNetwork()
    x_train, y_train, x_valid, y_valid  = loaddataset()
    
    p = population(n_population)
    
    
    current_retention_rate = max_retention_rate
    best_grade = np.inf
    previous_grade = np.inf
    previous_retention_rate = max_retention_rate
    fitness_history = [grade(model, p, x_train, y_train, x_valid, y_valid, target), ]
    for i in xrange(n_generation):
        p = evolve(model, p, x_train, y_train, x_valid, y_valid, target, 
                   retain=current_retention_rate,
                   random_select=random_select,
                   mutate=mutate)
        grade_ = grade(model, p, x_train, y_train, x_valid, y_valid, target)
        
        print 'Generation=%d grade=%f' % (i, grade_)
        fitness_history.append(grade_)
        
        if grade_ > previous_grade:
            current_retention_rate *= (1.0 - retention_rate_delta)
            if current_retention_rate < min_retention_rate:
                current_retention_rate = min_retention_rate
            else:
                print 'evolve: grade=%f > previous grade=%f, reducing retention from %f to %f' % \
                    (grade_, previous_grade, previous_retention_rate, current_retention_rate)
        else:
            current_retention_rate *= (1.0 + retention_rate_delta)
            if current_retention_rate > max_retention_rate:
                current_retention_rate = max_retention_rate
            else:
                print 'evolve: grade=%f < previous grade=%f, increasing retention from %f to %f' % \
                    (grade_, previous_grade, previous_retention_rate, current_retention_rate)
                
        previous_retention_rate = current_retention_rate
        previous_grade = grade_
        if grade_ <  best_grade: best_grade = grade_
    
    for i in fitness_history: print i
    
    print 'Best grade %f' % best_grade    
    best = find_best_individual(model, p, x_train, y_train, x_valid, y_valid, target)
    
    # Reports
    dict_ = dict(zip(chromosomes.keys(), best[0][1]))
    dict_.update(chromosomes_fixed)
    model.set_params(**dict_)
    print 'Best Model:', model
    print '%s' % chromosomes.keys() 
    for item in best: print item



if __name__=='__main__':
    main()
